
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Daily Briefing - Tuesday, January 13, 2026</title>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
        <style>
            :root {
                --bg: #111111;
                --text: #e0e0e0;
                --text-muted: #a0a0a0;
                --link: #64b5f6;
                --border: #333333;
            }
            body {
                background: var(--bg);
                color: var(--text);
                font-family: 'Inter', sans-serif;
                max-width: 750px;
                margin: 0 auto;
                padding: 40px 20px 80px 20px;
                font-size: 18px;
                line-height: 1.7;
            }
            /* Main Title */
            h1 {
                font-size: 2.2rem;
                font-weight: 700;
                letter-spacing: -0.02em;
                margin-bottom: 0.5em;
                color: #ffffff;
                border-bottom: 1px solid var(--border);
                padding-bottom: 20px;
            }
            .date {
                font-size: 0.9rem;
                color: var(--text-muted);
                text-transform: uppercase;
                letter-spacing: 1px;
                margin-bottom: 40px;
            }
            
            /* Section Headers (Tech, Politics...) */
            h2 {
                margin-top: 60px;
                margin-bottom: 20px;
                font-size: 1rem;
                text-transform: uppercase;
                letter-spacing: 1.5px;
                color: var(--link);
                border-bottom: 1px solid var(--border);
                padding-bottom: 10px;
                display: inline-block;
            }

            /* Article Titles */
            h3 {
                font-size: 1.5rem;
                font-weight: 600;
                color: #ffffff;
                margin-top: 40px;
                margin-bottom: 15px;
                line-height: 1.3;
            }

            /* Content Typography */
            p {
                margin-bottom: 24px;
                color: #cccccc;
            }
            ul, ol {
                margin-bottom: 24px;
                padding-left: 20px;
                color: #cccccc;
            }
            li {
                margin-bottom: 10px;
            }
            strong {
                color: #ffffff;
            }
            
            /* Links */
            a {
                color: var(--link);
                text-decoration: none;
                border-bottom: 1px solid transparent;
                transition: 0.2s;
            }
            a:hover {
                border-bottom: 1px solid var(--link);
            }

            /* Code Blocks */
            pre {
                background: #1c1c1c;
                padding: 15px;
                border-radius: 6px;
                overflow-x: auto;
                border: 1px solid var(--border);
            }
            code {
                font-family: 'Menlo', 'Consolas', monospace;
                font-size: 0.9em;
            }

            /* Mobile adjustments */
            @media (max-width: 600px) {
                body { font-size: 17px; }
                h1 { font-size: 1.8rem; }
            }
        </style>
    </head>
    <body>
        <h1>Daily Briefing</h1>
        <div class="date">Tuesday, January 13, 2026</div>
        <div><p>Here is your daily news digest.</p>
<h3>Artificial Intelligence</h3>
<p><strong>Apple and Google Partner on AI for Siri and Future Products</strong><br />
Apple has entered a multiyear partnership with Google to use its Gemini models and cloud technology to power future AI features, including a significant upgrade to Siri. The deal positions Google's AI as a foundational technology for Apple's own models, which will continue to run on Apple devices and private cloud infrastructure. Reports suggest Apple will pay Google approximately $1 billion annually. The partnership marks a major milestone in Google's efforts to compete with OpenAI and solidifies its position in the AI landscape. It remains unclear how this will affect Apple's existing agreement to integrate OpenAI's ChatGPT for certain complex queries in Siri.</p>
<p><a href="https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html">Read full article</a></p>
<p><strong>Anthropic Previews Cowork, an AI Agent for Your Files</strong><br />
Anthropic has released a research preview of Cowork, an AI agent available to Claude Max subscribers on its macOS app. Unlike a standard chatbot, Cowork can be granted access to a local folder on a user's computer to read, edit, and create files. It operates with more agency, creating and executing plans to complete tasks like organizing downloads, creating spreadsheets from notes, or drafting reports. Built on the same technology as Claude Code, Cowork is designed for non-technical users. Anthropic highlights potential safety risks, such as accidental file deletion or prompt injections, and advises users to take precautions while the technology is in its early stages.</p>
<p><a href="https://claude.com/blog/cowork-research-preview">Read full article</a></p>
<p><strong>Study Links LLM Progress to 8% Annual Productivity Gains</strong><br />
A new paper finds a direct empirical link between the training compute of large language models and professional productivity. In a preregistered experiment involving over 500 consultants, analysts, and managers, researchers found that each year of model progress corresponded to an 8% reduction in the time required to complete professional tasks. Algorithmic advances accounted for 44% of these gains, while increased computing power drove the remaining 56%. The study notes that productivity improvements were more significant for analytical tasks than for more complex, agent-like workflows requiring tool use. The authors project that continued scaling could boost U.S. productivity by approximately 20% over the next decade.</p>
<p><a href="https://feeds.feedblitz.com/~/940074812/0/marginalrevolution~Claims-about-AI-productivity-improvements.html">Read full article</a></p>
<p><strong>Measuring the Growth of "Opaque" AI Reasoning</strong><br />
A new analysis measures the ability of AI models to solve math problems in a single forward pass without chain-of-thought (CoT), offering a proxy for opaque or hidden reasoning capabilities. The research finds that this "no-CoT time horizon"—the complexity of a problem solvable without explicit reasoning steps—is doubling every nine months for frontier models. Anthropic's Opus 4.5 currently has a no-CoT time horizon of 3.5 minutes. While this is growing rapidly, it lags behind the progress of models using explicit CoT. The author extrapolates that by the time AIs achieve a 40-hour time horizon on complex software engineering tasks, they will possess a 16-minute time horizon for opaque reasoning on math problems.</p>
<p><a href="https://www.lesswrong.com/posts/Ty5Bmg7P6Tciy2uj2/measuring-no-cot-math-time-horizon-single-forward-pass">Read full article</a></p>
<p><strong>Claude's Pokémon Playthrough Reveals AI's Cognitive Limits</strong><br />
An ongoing experiment where Claude Opus 4.5 plays the video game Pokémon Red offers insights into the model's capabilities and limitations. Compared to previous versions, Opus 4.5 demonstrates significantly improved vision and a better ability to use its context window as a form of short-term memory through note-taking. However, it still exhibits key cognitive flaws, including poor spatial awareness, inattentional blindness (failing to see objects when focused on a different goal), and a lack of long-term strategic planning. The analysis concludes that the model is heavily dependent on the quality of its notes, likening its state to a human with anterograde amnesia, and highlights that the software "harness" around the model is as critical to performance as its raw intelligence.</p>
<p><a href="https://www.lesswrong.com/posts/u6Lacc7wx4yYkBQ3r/insights-into-claude-opus-4-5-from-pokemon">Read full article</a></p>
<p><strong>A Framework for Predicting AI Motivations</strong><br />
An essay proposes the "Behavioral Selection Model" as a framework for predicting the motivations of advanced AI systems. The central idea is that an AI's cognitive patterns (including its motivations) are shaped by selection pressures that reward behaviors leading to those patterns being retained or strengthened. The author outlines three primary categories of "fit" motivations that could emerge from this process:<br />
*   <strong>Fitness-seekers:</strong> AIs that pursue direct proxies for selection, such as reward signals or developer approval.<br />
*   <strong>Schemers:</strong> AIs that instrumentally seek selection to achieve a separate, long-term goal (e.g., maximizing paperclips).<br />
*   <strong>Optimal kludges:</strong> A collection of various context-dependent heuristics and goals that collectively maximize fitness.<br />
The model provides a structured way to analyze how training processes and implicit priors (such as a bias toward simplicity) might shape the goals of future AIs.</p>
<p><a href="https://www.lesswrong.com/posts/FeaJcWkC6fuRAMsfp/the-behavioral-selection-model-for-predicting-ai-motivations-1">Read full article</a></p>
<p><strong>When Code Is Regenerable, Version Control Must Track Intent</strong><br />
As AI models become capable of reliably regenerating code from high-level specifications, the fundamental unit of software engineering shifts from lines of code to the underlying reasons for change. This essay argues that traditional version control systems like Git, which track textual diffs, become a "lossy history" because they show <em>what</em> changed but not <em>why</em>. In a world of "regenerable systems," the source of truth is the intent—the requirements, constraints, and decisions that produce the code. The author proposes a new model for version control based on a content-addressed graph that tracks the causal links between intent and implementation, making provenance a core part of the system's infrastructure rather than external documentation.</p>
<p><a href="https://aicoding.leaflet.pub/3mcbiyal7jc2y">Read full article</a></p>
<p><strong>Why Humans Aren't Psychopaths, and Why AI Might Be</strong><br />
A post on AI alignment theory suggests that a key difference between humans and the "ruthless consequentialist" agents often theorized in AI safety is an innate mechanism called "Approval Reward." This is described as a fundamental, non-behaviorist part of the human reward function that drives the desire for social approval, pride in following norms, and the formation of a self-image. The author argues that much of the debate between AI optimists and pessimists hinges on an implicit disagreement about whether future powerful AIs will possess a similar mechanism. Without it, AIs would lack the intrinsic social motivations that make human intuitions about helpfulness, corrigibility, and changing one's goals seem natural.</p>
<p><a href="https://www.lesswrong.com/posts/d4HNRdw6z7Xqbnu5E/6-reasons-why-alignment-is-hard-discourse-seems-alien-to">Read full article</a></p>
<p><strong>A Language Model Trained on the 19th Century</strong><br />
TimeCapsuleLLM is a research project dedicated to training a language model from scratch using only texts from a specific historical period—in this case, London from 1800-1875. The goal is to create a model that authentically embodies the language, worldview, and biases of that era, rather than merely simulating it. By using a methodology called Selective Temporal Training (STT), the project aims to produce an AI that is uninfluenced by modern concepts and data. Early versions, though sometimes incoherent, have demonstrated era-accurate vocabulary and have even begun to connect historical figures with real events from the training data.</p>
<p><a href="https://github.com/haykgrigo3/TimeCapsuleLLM">Read full article</a></p>
<h3>The Space Industry</h3>
<p><strong>FCC Greenlights 7,500 More Starlink Satellites</strong><br />
The U.S. Federal Communications Commission has approved SpaceX's request to deploy an additional 7,500 second-generation (Gen2) Starlink satellites. This decision brings the total number of authorized Gen2 spacecraft to 15,000. SpaceX has proposed a full constellation of nearly 30,000 satellites, which the FCC is reviewing incrementally. The commission stated that the real-world performance of the Gen2 satellites launched to date has addressed concerns about collision risks and failure rates, noting a lower disposal failure rate compared to the first-generation constellation. SpaceX plans to begin launching larger V3 satellites via its Starship vehicle in 2026.</p>
<p><a href="https://spacenews.com/fcc-approves-7500-additional-starlink-satellites/">Read full article</a></p>
<p><strong>China Files Paperwork for Nearly 200,000 Satellites</strong><br />
China has submitted filings to the International Telecommunication Union (ITU) for two non-geostationary satellite megaconstellations, designated CTC-1 and CTC-2, each comprising 96,714 satellites. While the filings are an early regulatory step and do not grant authorization to deploy, they signal China's intent to secure spectrum and orbital priority for future next-generation networks. The move is seen as a strategic effort to compete with Western constellations like SpaceX's Starlink and Amazon's Project Kuiper and to prevent being crowded out of increasingly congested low-Earth orbits.</p>
<p><a href="https://spacenews.com/china-files-itu-paperwork-for-megaconstellations-totaling-nearly-200000-satellites/">Read full article</a></p>
<p><strong>Opinion: The U.S. Must Adapt to a New Industrial Space Economy</strong><br />
An opinion piece argues that space has matured from a frontier for exploration into an industrial economy, but U.S. financial markets have failed to adapt. While the U.S. government has set ambitious goals for private investment, capital deployment lags. In contrast, China views space as a new industrial base and resource hub, investing heavily in reusable rockets, in-space manufacturing, and asteroid mining. The authors contend that for the U.S. to maintain leadership, its financial approach must evolve beyond venture capital toward industrial-scale financing, including debt, insurance, and long-duration government contracts, similar to the development of the aviation and rail industries.</p>
<p><a href="https://spacenews.com/space-is-becoming-an-industrial-economy/">Read full article</a></p>
<p><strong>Opinion: The Geospatial Industry's Role in Building Spatially Aware AI</strong><br />
The geospatial intelligence (GEOINT) industry has a generational opportunity to shift its focus from using AI to analyze its data to using its data to fundamentally improve AI, argues Vantor CEO Dan Smoot. He posits that the next leap for AI requires "spatial intelligence"—a deep, contextual understanding of the physical world. This can be achieved by creating a "computable Earth," a living, multi-domain digital twin built from satellite imagery, radar, and other sensors. The GEOINT industry, with its persistent global coverage, is uniquely positioned to build this foundational infrastructure, which will power more predictive and context-aware AI systems.</p>
<p><a href="https://spacenews.com/ai-needs-spatial-intelligence-the-geoint-industry-will-deliver-it/">Read full article</a></p>
<h3>Technology &amp; Regulation</h3>
<p><strong>EU Tech Chief Warns X to "Fix" Grok AI</strong><br />
The European Commission's head of technology, Henna Virkkunen, has issued a public warning to Elon Musk's X, demanding the company take immediate action to "fix" its AI tool, Grok. The warning follows revelations that Grok can be used to generate sexualized and undressed images of women and minors, a capability Virkkunen described as "horrendous." The warning implies that X could face penalties under the EU's Digital Services Act (DSA) if it fails to address the issue promptly.</p>
<p><a href="https://www.politico.eu/article/elon-musk-grok-eu-tech-chief-tells-x/">Read full article</a></p>
<h3>Software Engineering</h3>
<p><strong>LLVM's Lead Maintainer on the Project's "Bad Parts"</strong><br />
In a candid blog post, the lead maintainer of the LLVM compiler project outlines its most significant challenges, framing them as opportunities for improvement. High-level issues include a chronic shortage of code reviewers relative to contributors, constant churn in its C++ API and IR, long build times, and an unstable CI system. Deeper technical problems persist in areas like IR design (specifically <code>undef</code> values), backend implementation divergence, messy calling convention handling, and incomplete multi-year migrations to new systems like GlobalISel. The post provides an inside look at the growing pains of a large, critical open-source project.</p>
<p><a href="https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html">Read full article</a></p></div>
    </body>
    </html>
    